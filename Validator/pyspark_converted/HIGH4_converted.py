from pyspark.sql.functions import col, when, avg, max, min, count, sum, groupBy, filter, collect_list, collect_set, collect_union, collect_distinct, collect_all, concat, explode, first, last, join, sort, orderBy, distinct, union, intersect, arrayUnion, arrayDifference, arrayIntersect, arrayExcept, arraySize, arrayLength, arrayCount, arrayMax, arrayMin, arrayAverage, arraySum, arrayFirst, arrayLast, arrayContains, arrayDoesNotContain, arrayAny, arrayAll, arrayNone, arrayIsEmpty, arrayIsNotEmpty, arrayContainsAll, arrayContainsAny, arrayContainsNone, arrayAnyOf, arrayAnyOfValues, arrayAllOf, arrayAnyOfValues, arrayAnyOfValues, arrayAllOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAllOfValues, arrayAnyOfValues, arrayAllOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, arrayAnyOfValues, array